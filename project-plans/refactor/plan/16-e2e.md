# Phase 16: End-to-End Testing Phase

## Phase ID

`PLAN-20250125-REFACTOR.P16`

## Prerequisites

- Required: Phase 15a (Deprecation Verification) completed
- Verification: `grep -r "@plan:PLAN-20250125-REFACTOR.P15A" project-plans/`
- Expected files from previous phase:
  - `project-plans/refactor/plan/.completed/P15A.md`
  - All deprecated code removed
  - Architecture clean and verified
  - All views functional
- Preflight verification: Phases 01-15a completed

## Purpose

Perform comprehensive end-to-end testing of the entire refactored system to verify all components work together correctly. This phase:

1. **Tests complete user workflows** from UI to services and back
2. **Verifies event flow** through entire system
3. **Tests error handling** across all layers
4. **Verifies data persistence** through service layer
5. **Tests performance** under realistic load

**Note:** This is the FINAL INTEGRATION phase. All previous phases must be complete.

## Requirements Implemented (Expanded)

### REQ-E2E.1: Complete Chat Workflow

**Full Text**: Complete chat workflow MUST work end-to-end (UI → Presenter → Service → LLM → Service → Presenter → UI).

**Behavior**:
- GIVEN: Application running with new architecture
- WHEN: User sends message through UI
- THEN: UserEvent emitted to EventBus
- AND: ChatPresenter receives event
- AND: ChatService called
- AND: LlmService makes API call
- AND: Response streams back via ViewCommands
- AND: UI updates progressively
- AND: Message saved to storage
- AND: No errors or crashes

**Why This Matters**: Verifies entire request/response pipeline works.

### REQ-E2E.2: Complete MCP Workflow

**Full Text**: Complete MCP server workflow MUST work end-to-end (UI → Presenter → Service → MCP Process → Service → Presenter → UI).

**Behavior**:
- GIVEN: Application running with new architecture
- WHEN: User starts MCP server
- THEN: UserEvent emitted
- AND: McpPresenter receives event
- AND: McpService starts process
- AND: Server status updates via ViewCommands
- AND: Tools listed in UI
- AND: Server remains running
- AND: User can stop server

**Why This Matters**: Verifies MCP integration works through new architecture.

### REQ-E2E.3: Complete Settings Workflow

**Full Text**: Complete settings workflow MUST work end-to-end (UI → Presenter → Service → Storage).

**Behavior**:
- GIVEN: Application running with new architecture
- WHEN: User updates profile
- THEN: UserEvent emitted
- AND: SettingsPresenter receives event
- AND: ProfileService updates profile
- AND: Notification sent via ViewCommand
- AND: Changes persist to storage
- AND: UI reflects changes

**Why This Matters**: Verifies configuration management through new architecture.

### REQ-E2E.4: Error Handling End-to-End

**Full Text**: Errors MUST be handled correctly across all layers and displayed to user.

**Behavior**:
- GIVEN: Application running
- WHEN: Error occurs at any layer (network, validation, etc.)
- THEN: Error event emitted to EventBus
- AND: ErrorPresenter receives event
- AND: ViewCommand::ShowError emitted
- AND: UI displays error dialog
- AND: Error logged appropriately
- AND: Application continues running

**Why This Matters**: Verifies robust error handling throughout system.

## Test Scenarios

### Scenario 1: New User Chat Workflow

**Steps**:
1. Launch application
2. Create new conversation
3. Select profile (e.g., GPT-4)
4. Send message: "Hello, can you help me?"
5. Verify thinking indicator shows
6. Verify response streams progressively
7. Verify thinking indicator hides
8. Verify message saved to history
9. Close and reopen application
10. Verify conversation persisted

**Expected Results**:
- [OK] Conversation created
- [OK] Message sent successfully
- [OK] Response received
- [OK] Streaming works smoothly
- [OK] Message persisted
- [OK] Conversation accessible after restart

**Logs to Verify**:
```
[ChatView] UserEvent::SendMessage emitted
[ChatPresenter] UserEvent::SendMessage received
[ChatService] send_message_stream called
[LlmService] API request initiated
[ChatPresenter] ViewCommand::ThinkingStarted emitted
[ChatView] Thinking indicator shown
[LlmService] Stream chunk received
[ChatPresenter] ViewCommand::AppendStream emitted
[ChatView] Message appended to UI
[LlmService] Stream complete
[ChatPresenter] ViewCommand::FinalizeStream emitted
[ChatView] Finalize stream
[ChatPresenter] ViewCommand::ThinkingEnded emitted
[ChatView] Thinking indicator hidden
[ConversationService] Message saved to storage
```

### Scenario 2: Multi-Turn Conversation

**Steps**:
1. Load existing conversation
2. Send follow-up message
3. Verify conversation context maintained
4. Send another message
5. Verify all messages visible
6. Verify conversation history complete

**Expected Results**:
- [OK] Conversation context maintained
- [OK] All messages in correct order
- [OK] History complete
- [OK] No duplicate messages

### Scenario 3: MCP Server Management

**Steps**:
1. Open MCP configuration view
2. Add new MCP server (e.g., filesystem server)
3. Configure server (command, args)
4. Start server
5. Verify server status shows "running"
6. Verify tools listed
7. Stop server
8. Verify server status shows "stopped"
9. Restart server
10. Verify server starts again

**Expected Results**:
- [OK] Server added to configuration
- [OK] Server starts successfully
- [OK] Tools enumerated
- [OK] Server status updates correctly
- [OK] Server stops successfully
- [OK] Server restarts successfully

**Logs to Verify**:
```
[McpView] UserEvent::StartMcpServer emitted
[McpPresenter] UserEvent::StartMcpServer received
[McpService] start_server called
[McpService] Spawning MCP process
[McpService] Waiting for tool enumeration
[McpService] Tools loaded: N
[McpPresenter] ViewCommand::McpServerStarted emitted
[McpView] Server status updated to running
```

### Scenario 4: Profile Management

**Steps**:
1. Open settings view
2. View existing profiles
3. Add new profile (e.g., Claude)
4. Configure profile (provider, model, API key)
5. Save profile
6. Verify notification shown
7. Set profile as default
8. Create new conversation with new profile
9. Send message
10. Verify correct profile used

**Expected Results**:
- [OK] Profile added successfully
- [OK] Profile details correct
- [OK] Notification displayed
- [OK] Default profile changed
- [OK] New conversation uses new profile
- [OK] API call to correct provider

**Logs to Verify**:
```
[SettingsView] UserEvent::UpdateProfile emitted
[SettingsPresenter] UserEvent::UpdateProfile received
[ProfileService] update_profile called
[ProfileService] Profile saved to storage
[SettingsPresenter] ViewCommand::ShowNotification emitted
[SettingsView] Notification displayed
```

### Scenario 5: Error Handling

**Steps**:
1. Try to send message with no network connection
2. Verify error displayed
3. Verify application doesn't crash
4. Try to start MCP server with invalid command
5. Verify error displayed
6. Try to update profile with invalid data
7. Verify validation error displayed
8. Verify all errors are logged

**Expected Results**:
- [OK] Network error displayed
- [OK] MCP error displayed
- [OK] Validation error displayed
- [OK] No crashes
- [OK] All errors logged
- [OK] Application remains functional

**Logs to Verify**:
```
[ErrorPresenter] Error event received
[ErrorPresenter] ViewCommand::ShowError emitted
[View] Error dialog displayed
[Error] Error logged to file
```

### Scenario 6: Performance Under Load

**Steps**:
1. Send 10 rapid messages in succession
2. Verify all messages processed
3. Verify no message loss
4. Verify no UI freezing
5. Check memory usage
6. Check event latency

**Expected Results**:
- [OK] All messages processed
- [OK] 0 message loss
- [OK] UI remains responsive
- [OK] Memory usage stable
- [OK] Event latency <100ms

### Scenario 7: Data Migration Verification

**Steps**:
1. Check backup exists
2. Verify conversation count matches pre-migration
3. Verify profile count matches pre-migration
4. Verify MCP config count matches pre-migration
5. Verify no data corruption
6. Verify all data accessible

**Expected Results**:
- [OK] Backup intact
- [OK] Counts match
- [OK] No corruption
- [OK] All data accessible

## Test Implementation

### Automated E2E Tests

#### `tests/e2e/chat_workflow.rs` (NEW FILE)

```rust
/// @plan PLAN-20250125-REFACTOR.P16
/// @requirement REQ-E2E.1
use std::time::Duration;
use tokio::time::sleep;

#[tokio::test]
async fn test_complete_chat_workflow() {
    // Initialize application
    let app = initialize_test_app().await;
    
    // Create conversation
    let conv_id = app.create_conversation().await.unwrap();
    assert!(!conv_id.is_nil());
    
    // Send message
    let response = app.send_message(conv_id, "Hello, world!").await.unwrap();
    assert!(!response.is_empty());
    
    // Verify message saved
    let messages = app.get_messages(conv_id).await.unwrap();
    assert_eq!(messages.len(), 2); // User + Assistant
    
    // Cleanup
    app.shutdown().await;
}

#[tokio::test]
async fn test_streaming_response() {
    let app = initialize_test_app().await;
    let conv_id = app.create_conversation().await.unwrap();
    
    // Send message and collect stream
    let chunks = app.send_message_stream(conv_id, "Tell me a story").await.unwrap();
    assert!(!chunks.is_empty());
    
    // Verify progressive streaming
    let mut prev_time = None;
    for (timestamp, _chunk) in chunks {
        if let Some(prev) = prev_time {
            let duration = timestamp - prev;
            assert!(duration.as_millis() < 500); // No long gaps
        }
        prev_time = Some(timestamp);
    }
    
    app.shutdown().await;
}
```

#### `tests/e2e/mcp_workflow.rs` (NEW FILE)

```rust
/// @plan PLAN-20250125-REFACTOR.P16
/// @requirement REQ-E2E.2
#[tokio::test]
async fn test_mcp_server_lifecycle() {
    let app = initialize_test_app().await;
    
    // Start MCP server
    let config = McpConfig::test_config();
    let server_id = app.start_mcp_server(config).await.unwrap();
    assert!(!server_id.is_nil());
    
    // Wait for server ready
    sleep(Duration::from_secs(2)).await;
    
    // Verify tools loaded
    let tools = app.list_mcp_tools(server_id).await.unwrap();
    assert!(!tools.is_empty());
    
    // Stop server
    app.stop_mcp_server(server_id).await.unwrap();
    
    app.shutdown().await;
}
```

#### `tests/e2e/settings_workflow.rs` (NEW FILE)

```rust
/// @plan PLAN-20250125-REFACTOR.P16
/// @requirement REQ-E2E.3
#[tokio::test]
async fn test_profile_management() {
    let app = initialize_test_app().await;
    
    // Add profile
    let profile = ModelProfile::test_profile();
    let profile_id = app.add_profile(profile.clone()).await.unwrap();
    assert!(!profile_id.is_nil());
    
    // List profiles
    let profiles = app.list_profiles().await.unwrap();
    assert!(profiles.iter().any(|(id, _)| *id == profile_id));
    
    // Update profile
    let mut updated = profile;
    updated.name = "Updated Name".to_string();
    app.update_profile(profile_id, updated).await.unwrap();
    
    // Verify update
    let loaded = app.get_profile(profile_id).await.unwrap();
    assert_eq!(loaded.name, "Updated Name");
    
    app.shutdown().await;
}
```

### Manual Test Procedures

#### Test Execution Checklist

**Pre-Test Setup**:
- [ ] Clean build: `cargo clean && cargo build --release`
- [ ] Verify data backup exists
- [ ] Clear logs: `rm -f ~/.personal-agent/debug.log`
- [ ] Start logging: `RUST_LOG=debug`

**Test Execution**:
1. [ ] Run Scenario 1: New User Chat Workflow
2. [ ] Run Scenario 2: Multi-Turn Conversation
3. [ ] Run Scenario 3: MCP Server Management
4. [ ] Run Scenario 4: Profile Management
5. [ ] Run Scenario 5: Error Handling
6. [ ] Run Scenario 6: Performance Under Load
7. [ ] Run Scenario 7: Data Migration Verification

**Post-Test Verification**:
- [ ] Review logs for errors
- [ ] Check data integrity
- [ ] Verify no crashes
- [ ] Document any issues

## Verification Commands

### Structural Verification

```bash
# Verify E2E test files exist
ls -la tests/e2e/*.rs
# Expected: chat_workflow.rs, mcp_workflow.rs, settings_workflow.rs

# Verify plan markers
grep -r "@plan:PLAN-20250125-REFACTOR.P16" tests/e2e/*.rs | wc -l
# Expected: 10+ occurrences

# Verify requirement markers
grep -r "@requirement:REQ-E2E" tests/e2e/*.rs | wc -l
# Expected: 4+ occurrences
```

### Semantic Verification

```bash
# Run E2E tests
cargo test --test e2e 2>&1 | tee e2e_test.log

# Check test results
grep -E "test result:" e2e_test.log | tail -1
# Expected: test result: ok. X passed in Ys

# Verify no failures
grep -E "FAILED" e2e_test.log
# Expected: 0 matches

# Verify test coverage
grep -E "test.*chat|test.*mcp|test.*settings" e2e_test.log | wc -l
# Expected: 10+ tests
```

### Manual Test Verification

```bash
# Start application with debug logging
RUST_LOG=debug cargo run --release 2>&1 | tee manual_test.log

# Verify event flow in logs
grep -E "UserEvent emitted|Presenter received|ViewCommand emitted" manual_test.log | wc -l
# Expected: 20+ event flow markers

# Check for errors
grep -E "ERROR|panic|crash" manual_test.log
# Expected: 0 matches

# Verify performance
grep -E "Event latency|Processing time" manual_test.log
# Expected: All events <100ms
```

## Success Criteria

- All E2E test scenarios pass
- Automated E2E tests pass (10+ tests)
- Manual testing completes successfully
- No errors or crashes
- Event flow verified in logs
- Data integrity verified
- Performance acceptable
- No regressions detected
- All user workflows functional
- Error handling verified

## Failure Recovery

If E2E testing fails:

1. **Identify Failure Point**:
   ```bash
   grep -E "FAILED|ERROR|panic" e2e_test.log manual_test.log
   ```

2. **Debug Specific Scenario**:
   - Re-run failed scenario
   - Enable detailed logging
   - Trace event flow

3. **Fix Issue**:
   - Fix bug in relevant layer
   - Verify fix with targeted test
   - Re-run E2E tests

4. **Document Issues**:
   - Log any known issues
   - Create follow-up tasks
   - Decide if blocking for release

## Phase Completion Marker

Create: `project-plans/refactor/plan/.completed/P16.md`

Contents:

```markdown
Phase: P16
Completed: YYYY-MM-DD HH:MM
Test Scenarios Executed:
  - Scenario 1 (New User Chat): PASS
  - Scenario 2 (Multi-Turn Conversation): PASS
  - Scenario 3 (MCP Server Management): PASS
  - Scenario 4 (Profile Management): PASS
  - Scenario 5 (Error Handling): PASS
  - Scenario 6 (Performance Under Load): PASS
  - Scenario 7 (Data Migration Verification): PASS

Automated Tests:
  - Total E2E tests: N
  - Passed: N
  - Failed: 0

Manual Testing:
  - All workflows: VERIFIED
  - Error handling: VERIFIED
  - Performance: ACCEPTABLE
  - Data integrity: VERIFIED

System Status:
  - Application: STABLE
  - No crashes: VERIFIED
  - No data loss: VERIFIED
  - Performance: ACCEPTABLE

Architecture Verification:
  - Event flow: CORRECT
  - Presenter layer: FUNCTIONAL
  - Service layer: FUNCTIONAL
  - UI integration: COMPLETE

Notes:
  - All end-to-end tests passed
  - System stable and functional
  - Ready for production use
  - Refactor complete
```

## Next Steps

After successful completion of this phase:

1. Proceed to Phase 16a: E2E Verification
2. Document any known issues
3. Create final refactor report
4. Celebrate successful refactor! 

## Important Notes

- **COMPREHENSIVE TESTING**: Test all user workflows
- **MANUAL TESTING REQUIRED**: Cannot fully automate UI testing
- **LOG REVIEW**: Review all logs for issues
- **PERFORMANCE**: Verify acceptable performance
- **STABILITY**: No crashes or hangs
- **DATA INTEGRITY**: Critical verification
- **FINAL PHASE**: This is the last integration phase
